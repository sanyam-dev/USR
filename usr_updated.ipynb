{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtNatBXECTsq",
        "outputId": "2ce060bd-4530-47dc-d43a-4d3bdc28fcba"
      },
      "outputs": [],
      "source": [
        "markers = {\"Ora\", \"evaM\", \"waWA\", \"agara\", \"yaxi\", \"wo\", \"kyoMki\",\n",
        "\t\t\t\t\t\"isIlie\",\"jabaki\",\"yaxyapi\",\"waWApi\",\"yaxyapi\",\"Pira BI\",\n",
        "\t\t\t\t\t\"lekina\",\"kiMwu\",\"paraMwu\",\"jaba\",\"waba\",\"yA\",\"aWavA\"}\n",
        "\n",
        "\n",
        "discourse_relation = {\n",
        "\t\"Ora\" : \"samuccaya\",\n",
        "\t\"evaM\" : \"samuccaya\",\n",
        "\t\"waWA\" : \"samuccaya\",\n",
        "\t\"agara\" : \"AvaSyakwA-pariNAma\",\n",
        "\t\"yaxi\" : \"AvaSyakwA-pariNAma\",\n",
        "\t\"wo\" : \"AvaSyakwA-pariNAma\",\n",
        "\t\"kyoMki\" : \"kArya-kAraNa\",\n",
        "\t\"isIlie\" : \"kArya-kAraNa\",\n",
        "\t\"jabaki\" : \"vyABicAra\",\n",
        "\t\"yaxyapi\" : \"vyABicAra\",\n",
        "\t\"waWApi\" : \"vyABicAra\",\n",
        "\t\"Pira BI\" : \"vyABicAra\",\n",
        "\t\"lekina\" : \"viroXi\",\n",
        "\t\"kiMwu\" : \"viroXi\",\n",
        "\t\"paraMwu\" : \"viroXi\",\n",
        "\t\"jaba\" : \"samAnakAla\",\n",
        "\t\"waba\": \"samAnakAla\",\n",
        "\t\"yA\": \"anyawra\",\n",
        "\t\"aWavA\": \"anyawra\",\n",
        "}\n",
        "\n",
        "# 0: previous usr\n",
        "# 1: current usr\n",
        "\n",
        "discourse_pos = {\n",
        "\t\"samuccaya\" : \"1\",\n",
        "\t\"anyawra\": \"1\",\n",
        "\t\"samAnakAla\":\"0\",\n",
        "\t\"viroXi\": \"1\",\n",
        "\t\"vyaBicAra\":\"0\",\n",
        "\t\"kArya-kAraNa\": \"0\",\n",
        "\t\"AvaSyakwA-pariNAma\": \"0\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "USR input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZf1i2wSpjp8"
      },
      "outputs": [],
      "source": [
        "prev_usr = [[\"Apa cAhawe hEM\"],[\"addressee\",\"cAha_1-wA_hE_1\"],[1,2],\n",
        "[\"anim\"],\n",
        "[\"m\", \"sg\", \"u\"],\n",
        "[\"2:k1\",\"? 0:main\"],\n",
        "[],\n",
        "[\"affirmative\"]]\n",
        "\n",
        "curr_usr = [[\"wo meM Apake Gara AuzgA\"],[], [], [], [], [\"4:k1\", \"3:r6\", \"4:k2p\", \"4:main\"], [], []]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd7f9IrUYokB"
      },
      "source": [
        "l1 = [[\"Apa cAhawe hEM\"],\n",
        "[\"addressee\",\"cAha_1-wA_hE_1\"],\n",
        "[1,2]\n",
        "[\"anim\",]\n",
        "[\"m\", \"sg\", \"u\"],\n",
        "[2:k1,0:main],\n",
        "[2.4:Avash;],\n",
        "[affirmative]\n",
        "]\n",
        "\n",
        "l2 = [wo meM Apake Gara AuzgA\n",
        "speaker,addressee,Gara_1,A_1-gA_1\n",
        "1,2,3,4\n",
        "anim,,,\n",
        "[- sg u],,[- sg a],\n",
        "[4:k1,3:r6,4:k2p,0:main]\n",
        ",,,\n",
        ",respect,,\n",
        ",,,\n",
        "]:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "process USR\n",
        "\n",
        "import wxconv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wxconv import WXC\n",
        "import os\n",
        "con = WXC(order='utf2wx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wxconv import WXC\n",
        "import os\n",
        "con = WXC(order='wx2utf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = \"##इसीलिए उस्को परीक्षा मे लिखने की अनुमति नहीं मिली\"\n",
        "print(con.convert(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = \"isake pariNAma svarupa abbs bbbbs\"\n",
        "sentence = ['BUgola', 'kA', 'eka', 'anya', 'pakRa'] \n",
        "for i in range(1, len(sentence)  + 1):\n",
        "\t\t\t\tpos = 0\n",
        "\t\t\t\tfor _ in range(0, len(sentence) - i + 1):\n",
        "\t\t\t\t\ts = sentence[pos:pos+i]\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tpos += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "s = con.convert(\"संपूण सूयार्वस्त\")\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_res_folder(path):\n",
        "\ttry:\n",
        "\t\tos.makedirs(path)\n",
        "\texcept FileExistsError:\n",
        "\t\tprint(\"error, folder already exists\")\n",
        "\t\t# filename += str(random.randint(0,100))\n",
        "\t\t# path = os.path.join(parent_dir, filename)\n",
        "\t\t# os.makedirs(path)\n",
        "\treturn path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_usr(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        return [string.split(\",\") for string in content.split(\"\\n\")]\n",
        "        # print(content_usr_list)\n",
        "\t\t\t\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_usr_to_txt(prev_usr, prev_filename,  sub_folder_path):\n",
        "    with open(sub_folder_path + \"/\" + prev_filename + '.txt', \"w\") as file:\n",
        "        for usr_entry in prev_usr:\n",
        "            for item in usr_entry:\n",
        "                file.write(item + \",\")\n",
        "            file.write(\"\\n\")\n",
        "        file.close()\n",
        "    print(\"data written\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# returns discourse relation for a given string (use curr_usr string)\n",
        "def mpd(str2):\n",
        "\twords1 = str2.split()\n",
        "\tfor word in words1:\n",
        "\t\tprint(word)\n",
        "\t\tif word in markers:\n",
        "\t\t\t#print(word)\n",
        "\t\t\treturn discourse_relation[word]\n",
        "\t\n",
        "\treturn \"-1\"\n",
        "\n",
        "def get_main_str(usr):\n",
        "\tstrings_with_main = \"\"\n",
        "\tfor item in usr[5]:\n",
        "\t\tif item and item.endswith(\":main\"):\n",
        "\t\t\trest_of_string = item[-7:-5]\n",
        "\t\t\tstrings_with_main += rest_of_string\n",
        "\treturn strings_with_main\n",
        "\t\n",
        "def process_usr(prev_filename, prev_usr, curr_filename, curr_usr):\n",
        "\t\tstr1 = curr_usr[0][0][1:]\n",
        "\t\tstr1 = con.convert(str1)\n",
        "\t\tprint(\"str: \" , str1)\n",
        "\t\tdiscourse_rel = mpd(str1)\n",
        "\t\tif(discourse_rel == \"-1\"):\n",
        "\t\t\treturn prev_usr, curr_usr\n",
        "\t\ty = discourse_pos[discourse_rel]\n",
        "\t\t# y == 0  means discourse relation to be added to prev_usr\n",
        "\t\t# y == 1  means discourse relation to be added to curr_usr\n",
        "\t\tif y == 0:\n",
        "\t\t\t# find main of curr_usr\n",
        "\t\t\tstrings_with_main = get_main_str(curr_usr)\n",
        "\t\t\tusr_id = curr_filename\n",
        "\t\t\tfin = usr_id + \".\" + strings_with_main + \":\" + discourse_rel\n",
        "\t\t\tposition_of_discourse = int(strings_with_main)\n",
        "\t\t\tprev_usr[6][position_of_discourse] = fin\n",
        "\t\t\t# fin = usr_id + \".\" + strings_with_main\n",
        "\t\telse:\n",
        "\t\t\tstrings_with_main = get_main_str(prev_usr)\n",
        "\t\t\tusr_id = prev_filename\n",
        "\t\t\tfin = usr_id + \".\" + strings_with_main + \":\" + discourse_rel\n",
        "\t\t\tposition_of_discourse = int(strings_with_main)\n",
        "\t\t\tcurr_usr[6][position_of_discourse] = fin\n",
        "\t\t\n",
        "\t\treturn prev_usr, curr_usr\n",
        "\t\t\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM4NRffHpf2C"
      },
      "source": [
        "Parse all files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI8dJODDse5g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "res_folder = \"./results_test\"\n",
        "create_res_folder(res_folder)\n",
        "\n",
        "for folder_name, sub_folder, filenames in os.walk(root_folder):\n",
        "\tprint(\"foldername \", folder_name)\n",
        "\tprint(\"subfolder\", sub_folder)\n",
        "\tprint(\"filename: \" , filenames)\n",
        "\t\n",
        "\tif sub_folder.__sizeof__ != 0:\n",
        "\t\t\n",
        "\t\tfor sub_folder_name in sub_folder:\n",
        "\t\t\tsub_folder_path = root_folder +  \"/\" + sub_folder_name\n",
        "\t\t\t# print(sub_folder_path)\n",
        "\t\t\tpath = res_folder + \"/\" + sub_folder_name \n",
        "\t\t\tcreate_res_folder(path)\n",
        "\t\t\tfor _, _, filenames in os.walk(sub_folder_path): \n",
        "\t\t\t\tfilenames = sorted(filenames)\n",
        "\t\t\t\t\n",
        "\t\t\t\tprev_usr = []\n",
        "\t\t\t\tcurr_usr = []\n",
        "\t\t\t\tprev_filename = \"0\"\n",
        "\t\t\t\tfor filename in filenames:\n",
        "\t\t\t\t\tfile_path\t= sub_folder_path + \"/\" + filename\n",
        "\t\t\t\n",
        "\t\t\t\t\twith open(file_path, \"r\") as file:\n",
        "\t\t\t\t\t\t\tcontent = file.read()\n",
        "\t\t\t\t\t\t\tprint(filename, \":->\", len(content), \":->>\", content.find(\"\\n\"))\n",
        "\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\tif content.find(\"\\n\") != -1:\n",
        "\t\t\t\t\t\t\t\tcurr_usr = convert_to_usr(file_path)\n",
        "\t\t\t\t\t\t\t\tprev_usr, curr_usr = process_usr(prev_filename, prev_usr, filename, curr_usr)\n",
        "\t\t\t\t\t\t\t\tsave_usr_to_txt(prev_usr, prev_filename, path)\n",
        "\t\t\t\t\t\t\t\tsave_usr_to_txt(curr_usr, filename, path)\n",
        "\t\t\t\t\t\t\t\tprev_filename = filename\n",
        "\t\t\t\t\t\t\t\tprev_usr = curr_usr\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t\t# fn(prev_usr, curr_usr)\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t# content.find(\"\\n\")\n",
        "\t\t\t\t\t\t\t# hindi_str = content.partition(\"\\n\")\n",
        "\t\t\t\t\t\t\t# print(hindi_str)\n",
        "\t\t\t\tbreak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from usr import USR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "usr = USR()\n",
        "input_dir = \"./data\"\n",
        "output_dir = \"./res\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "usr.set_root_folder_path(input_dir)\n",
        "usr.set_res_folder_path(output_dir)\n",
        "usr.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = \"./t1/s1/Geo_nios_1ch_0027a\"\n",
        "with open(p, 'r') as file:\n",
        "\tcontent = file.read()\n",
        "\tUSR_list = content.split(\"\\n\")\n",
        "\tfor i in range(len(USR_list)):\n",
        "\t\tif i == 0:\n",
        "\t\t\t# USR_list[i] = USR_list[i].split(\" \")\n",
        "\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tUSR_list[i] = USR_list[i].split(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(USR_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "curr_usr = USR_list\n",
        "s = curr_usr[0]\t#taking the sentence\n",
        "str1 = s[1:]\t#removing '#' symbol\n",
        "str1 = con.convert(str1) #converting to wx notation\n",
        "str1 = str1.split(\" \")[:5]\t#taking the first 5 words from the beginning of the sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "str1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "for _, _, files in os.walk(\"./example/example_subfolder\"):\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from usr import discourseMarkerParser\n",
        "import wxconv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = discourseMarkerParser(\"1a आप चाहते हैं\", \"1b तो में आपके घर आउँगा\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1, x2, x3 = x.get_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Apa cAhawe hEM AvaSyakwA-pariNAma wo meM Apake Gara AuzgA\n"
          ]
        }
      ],
      "source": [
        "print(x1, x2, x3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
